{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic scVI Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'basic_tutorial.config.json'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f7219f22e6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'basic_tutorial.config.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'basic_tutorial.config.json'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.chdir(\"../..\")\n",
    "import json\n",
    "with open('basic_tutorial.config.json') as f:\n",
    "    config = json.load(f)\n",
    "print(config)\n",
    "\n",
    "n_epochs_all = config['n_epochs'] if 'n_epochs' in config else None\n",
    "save_path = config['save_path'] if 'save_path' in config else 'data/'\n",
    "n_samples_tsne = config['n_samples_tsne'] if 'n_samples_tsne' in config else None\n",
    "n_samples_posterior_density = config['n_samples_posterior_density'] if 'n_samples_posterior_density' in config else None\n",
    "train_size = config['train_size'] if 'train_size' in config else None\n",
    "M_sampling_all = config['M_sampling'] if 'M_sampling' in config else None\n",
    "M_permutation_all = config['M_permutation'] if 'M_permutation' in config else None\n",
    "rate = config['rate'] if 'rate' in config else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scvi.dataset import CortexDataset, RetinaDataset\n",
    "\n",
    "from scvi.models import *\n",
    "from scvi.inference import UnsupervisedTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "Here we load the CORTEX dataset described in\n",
    "\n",
    "* Zeisel, Amit, et al. \"Cell types in the mouse cortex and hippocampus revealed by single-cell RNA-seq.\" Science 347.6226 (2015): 1138-1142. \n",
    "\n",
    "Please see our data loading Jupyter notebook for more examples of data loading -- scVI has many \"built-in\" datasets, as well as support for loading arbitrary .csv, .loom, and .h5ad (AnnData) files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/expression.bin already downloaded\n",
      "Preprocessing Cortex data\n",
      "Finished preprocessing Cortex data\n",
      "labels: [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 6 6 5 6 6 5 6 5 6 6 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 6 6 6 5 5 5 5 5 5 5 6 5 6 5 5 6 5 5 6 6 6 6 6 6 6 5 6 6 6 5\n",
      " 6 6 6 6 6 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1]\n",
      "n_labels: 7\n",
      "cell_types: ['astrocytes_ependymal' 'endothelial-mural' 'interneurons' 'microglia'\n",
      " 'oligodendrocytes' 'pyramidal CA1' 'pyramidal SS']\n"
     ]
    }
   ],
   "source": [
    "gene_dataset = CortexDataset(save_path=save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __n_epochs__: Maximum number of epochs to train the model. If the likelihood change is small than a set threshold training will stop automatically. \n",
    "* __lr__: learning rate. Set to 0.001 here. \n",
    "* __use_batches__: If the value of true than batch information is used in the training. Here it is set to false because the cortex data only contains one batch. \n",
    "* __use_cuda__: Set to true to use CUDA. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=400 if n_epochs_all is None else n_epochs_all\n",
    "lr=1e-3\n",
    "use_batches=False\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model and output model likelihood every 5 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VAE' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92d413cedacd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgene_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_genes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgene_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_batches\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0muse_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m trainer = UnsupervisedTrainer(vae,\n\u001b[1;32m      3\u001b[0m                               \u001b[0mgene_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VAE' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "vae = VAE(gene_dataset.nb_genes, n_batch=gene_dataset.n_batches * use_batches)\n",
    "trainer = UnsupervisedTrainer(vae,\n",
    "                              gene_dataset,\n",
    "                              train_size=0.75,\n",
    "                              use_cuda=use_cuda,\n",
    "                              frequency=5)\n",
    "trainer.train(n_epochs=n_epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Plotting the likelihood change across the 500 epochs of training: blue for training error and orange for testing error. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_train_set = trainer.history[\"ll_train_set\"]\n",
    "ll_test_set = trainer.history[\"ll_test_set\"]\n",
    "x = np.linspace(0,500,(len(ll_train_set)))\n",
    "plt.plot(x, ll_train_set)\n",
    "plt.plot(x, ll_test_set)\n",
    "plt.ylim(1150,1600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plt_labels: ['astrocytes_ependymal' 'endothelial-mural' 'interneurons' 'microglia'\n",
      " 'oligodendrocytes' 'pyramidal CA1' 'pyramidal SS']\n"
     ]
    }
   ],
   "source": [
    "trainer.train_set.show_t_sne(n_samples=n_samples_tsne, color_by='labels', save_name=\"basic_t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the latent space for the whole dataset\n",
    "\n",
    "This will return in a np.array the mean of the posterior distribution p(z|x) where x is the data whose latent representation we want. In the np.array giving the latent space, the cells are in the same order as in the original dataset matrix. As you can see in the imputation section, the get_all_latent_and_imputed_values method provides more information than just the latent space, it is a dictionary that contains the latent space, the imputed values, the labels and batch indices of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent = trainer.get_all_latent_and_imputed_values()[\"latent\"]\n",
    "#in order to save the latent space you can either use numpy.save \n",
    "#or if you want it as a .csv file you can add arguments to the method get_dataset_information which will do it\n",
    "latent = trainer.get_all_latent_and_imputed_values(save_latent=True, file_name_latent=\"Cortex_dataset_latent_space\")[\"latent\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "\n",
    "\n",
    "The ability to impute missing values is useful in practical applications in addition to providing an assay for generalization performance. In the following analysis, we benchmark scVI against BISCUIT, ZINB-WaVE and ZIFA, as well as MAGIC, which provides imputation without explicit statistical modeling. To evaluate these methods on a given dataset, we generated a **corrupted training set**, and then fitted the perturbed dataset with each of the benchmark methods and evaluate them by comparing the imputed values to the original ones (Methods 4.7). Overall, we observe that the imputation accuracy of scVI is higher or comparable (less than one transcript for median error) across all datasets\n",
    "\n",
    "#### Corrupting the datasets for imputation benchmarking. \n",
    "\n",
    "Two different approaches to measure the robustness of algorithms to noise in the data: \n",
    "\n",
    "- **Uniform zero introduction**: select randomly a rate r% of the non-zero entries and multiply the entry n with a Ber(0.9) random variable.\n",
    "- **Binomial data corruption**: select a rate r% of the matrix and replace an entry n by a Bin(n, 0.2) random variable.\n",
    "\n",
    "By default, the rate r is set a 0.1\n",
    "\n",
    "#### Accuracy of imputing missing data \n",
    "\n",
    "As imputation tantamount to replace missing data by its mean conditioned on being observed, we use the median L1 distance between the original dataset and the imputed values for corrupted entries only.\n",
    "Parameters:\n",
    "* The rate of simulated dropout is defined by __rate__, here set ot 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 400/400 [05:43<00:00,  1.17it/s]\n",
      "\n",
      "Median of Median: 2.4180\n",
      "Mean of Median for each cell: 3.5523\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 400 if n_epochs_all is None else n_epochs_all\n",
    "vae = VAE(gene_dataset.nb_genes, n_batch=gene_dataset.n_batches * use_batches)\n",
    "trainer = UnsupervisedTrainer(vae,\n",
    "                              gene_dataset,\n",
    "                              train_size=0.75 if train_size is None else train_size,\n",
    "                              use_cuda=use_cuda)\n",
    "\n",
    "trainer.corrupt_posteriors(rate=0.1, corruption=\"uniform\")\n",
    "trainer.train(n_epochs)\n",
    "trainer.uncorrupt_posteriors()\n",
    "\n",
    "original_list, imputed_list = trainer.train_set.imputation_benchmark(verbose=True, n_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.418014\n"
     ]
    }
   ],
   "source": [
    "# Median of medians for all distances\n",
    "imputation_errors = np.abs(np.concatenate(original_list) - np.concatenate(imputed_list))\n",
    "median_imputation_score = np.median(imputation_errors)\n",
    "print(median_imputation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the distribution of absolute errors between the imputed value and the true value at the dropout positions. \n",
    "\n",
    "Note: The imputed value __px_rate__ is the rate parameter (expected value) of the Zero-Inflated Negative Binomial (ZINB) distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 3.000e+00, 6.000e+00, 2.900e+01, 2.570e+02, 1.891e+03,\n",
       "        5.131e+03, 1.474e+03, 7.300e+01, 9.000e+00]),\n",
       " array([-5.37962198, -4.48792462, -3.59622726, -2.70452991, -1.81283255,\n",
       "        -0.92113519, -0.02943783,  0.86225953,  1.75395689,  2.64565425,\n",
       "         3.53735161]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(np.log10(imputation_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing without artificial corruption\n",
    "\n",
    "Through the imputation benchmark above, we have assessed the strength of scVI for this task. \n",
    "\n",
    "To actually perform the imputation on a model trained on regular data, we might use the `.imputation` method. As stochasticity of the training requires iteration on permuted samples of the data, the output result is in random order. \n",
    "\n",
    "To get an ordered output result, we might use `.sequential` posterior's method which return another instance of posterior (with shallow copy of all its object references), but where the iteration is in the same ordered as its  indices attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_values_unordered = trainer.train_set.imputation()\n",
    "\n",
    "indices = trainer.train_set.indices # The indices in the order that they will be processed with .sequential()\n",
    "#These indices correspond to the indices of the cells in the input counts matrix vae.gene_dataset.X\n",
    "imputed_values_indices = trainer.train_set.sequential().imputation() # imputation result ordered along indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the imputed values for the whole dataset after the training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_values = trainer.get_all_latent_and_imputed_values()[\"imputed_values\"]\n",
    "#in order to save it you can either use numpy.save \n",
    "#or if you want it as a .csv file you can add arguments to the method get_dataset_information which will do it\n",
    "imputed_values = trainer.get_all_latent_and_imputed_values(save_imputed=True, file_name_imputation=\"Cortex_dataset_imputed_values\")[\"imputed_values\"]\n",
    "#there is another optional argument: the boolean save_shape_genes_by_cells \n",
    "#so you can choose according to which format you prefer to save the expression matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Expression\n",
    "From the trained VAE model we can sample the gene expression rate for each gene in each cell. For the two populations of interest, we can then randomly sample pairs of cells, one from each population to compare their expression rate for a gene. The degree of differential expression is measured by __logit(p/(1-p))__ where __p__ is the probability of a cell from population A having a higher expression than a cell from population B. We can form the null distribution of the DE values by sampling pairs randomly from the combined population.\n",
    "\n",
    "The following example is implemented for the cortext dataset, vary __cell_types__ and __genes_of_interest__ for other datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Set population A and population B for comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['astrocytes_ependymal' 'endothelial-mural' 'interneurons' 'microglia'\n",
      " 'oligodendrocytes' 'pyramidal CA1' 'pyramidal SS']\n",
      "\n",
      "Differential Expression A/B for cell types\n",
      "A: oligodendrocytes\n",
      "B: pyramidal CA1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cell_types = gene_dataset.cell_types\n",
    "print(gene_dataset.cell_types)\n",
    "# oligodendrocytes (#4) VS pyramidal CA1 (#5)\n",
    "couple_celltypes = (4, 5)  # the couple types on which to study DE\n",
    "\n",
    "print(\"\\nDifferential Expression A/B for cell types\\nA: %s\\nB: %s\\n\" %\n",
    "      tuple((cell_types[couple_celltypes[i]] for i in [0, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Define parameters**\n",
    "* __M_sampling__: the number of times to sample __px_scales__ from the vae model for each gene in each cell.\n",
    "* __M_permutation__: Number of pairs sampled from the px_scales values for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_sampling = 100 if M_sampling_all is None else M_sampling_all\n",
    "\n",
    "M_permutation = 100000  if M_permutation_all is None else M_permutation_all\n",
    "permutation = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Sample from the gene expression level from all cells**\n",
    "Note: The expectation of the ZINB distribution __px_rate ~ library_size * px_scale__, so __px_scale__ could be understood as the mean gene expression level of each cell after adjusting for the library size factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "px_scale, all_labels = trainer.train_set.differential_expression_stats(M_sampling=M_sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Extract the sampled gene expression level for the two populations of interest, and create indexes for the samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate_a = px_scale[(all_labels == couple_celltypes[0]).ravel()].reshape(-1, px_scale.shape[1])\n",
    "sample_rate_b = px_scale[(all_labels == couple_celltypes[1]).ravel()].reshape(-1, px_scale.shape[1])\n",
    "\n",
    "list_1 = list(np.arange(sample_rate_a.shape[0]))\n",
    "list_2 = list(sample_rate_a.shape[0] + np.arange(sample_rate_b.shape[0]))\n",
    "\n",
    "samples = np.vstack((sample_rate_a, sample_rate_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Compute whether a gene is differentially expressed by computing pairs of cells from population A and population B**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = np.random.choice(list_1, size=M_permutation), np.random.choice(list_2, size=M_permutation)\n",
    "first_set = samples[u]\n",
    "second_set = samples[v]\n",
    "res1 = np.mean(first_set >= second_set, 0)\n",
    "res1 = np.log(res1 + 1e-8) - np.log(1 - res1 + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Obtaining the null value by comparing pairs sampled from the combined population**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = (np.random.choice(list_1 + list_2, size=M_permutation),\n",
    "    np.random.choice(list_1 + list_2, size=M_permutation))\n",
    "first_set = samples[u]\n",
    "second_set = samples[v]\n",
    "res2 = np.mean(first_set >= second_set, 0)\n",
    "res2 = np.log(res2 + 1e-8) - np.log(1 - res2 + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print out the differential expression value from both the true comparison and the permuted comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thy1 : -5.74453613852952 , 0.0010800000833760537\n",
      "Mbp : 5.447166996632846 , -0.0007200000167042475\n"
     ]
    }
   ],
   "source": [
    "genes_of_interest = [\"Thy1\", \"Mbp\"]\n",
    "gene_names = gene_dataset.gene_names\n",
    "result = [(gene_name, res1[np.where(gene_names == gene_name.upper())[0]][0],res2[np.where(gene_names == gene_name.upper())[0]][0]) for gene_name in genes_of_interest]\n",
    "print('\\n'.join([gene_name + \" : \" + str(r1) + \" , \"+ str(r2) for (gene_name, r1,r2) in result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1-7. Step one through seven obtained with a single line **\n",
    "\n",
    "Give as argument the two cell types and genes of interest and it will return the list of the bayes factor score for each gene in the same order specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_factors_list = trainer.train_set.differential_expression_score(\n",
    "    'oligodendrocytes', 'pyramidal CA1',\n",
    "    M_sampling=M_sampling,\n",
    "    M_permutation=M_permutation,\n",
    "    genes= [\"THY1\", \"MBP\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Plot the null distribution of the DE values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,  19.,  38.,  64.,  98., 129., 112.,  64.,  24.,   7.]),\n",
       " array([-0.01632036, -0.0132643 , -0.01020824, -0.00715218, -0.00409612,\n",
       "        -0.00104006,  0.002016  ,  0.00507206,  0.00812812,  0.01118418,\n",
       "         0.01424024]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Visualize top 10 most expressed genes per cell types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fc627e3ac50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes, expression = trainer.train_set.differential_expression_table(M_sampling=M_sampling)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "im = plt.imshow(expression, cmap='RdYlGn', interpolation='none', aspect='equal')\n",
    "ax = plt.gca()\n",
    "ax.set_xticks(np.arange(0, 7, 1))\n",
    "ax.set_xticklabels(gene_dataset.cell_types, rotation='vertical')\n",
    "ax.set_yticklabels(genes)\n",
    "ax.set_yticks(np.arange(0, 70, 1))\n",
    "ax.tick_params(labelsize=14)\n",
    "plt.colorbar(shrink=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correction for batch effects\n",
    "\n",
    "First we load the RETINA dataset that is described in\n",
    "\n",
    "* Shekhar, Karthik, et al. \"Comprehensive classification of retinal bipolar neurons by single-cell transcriptomics.\" Cell 166.5 (2016): 1308-1323."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/retina.loom already downloaded\n",
      "Preprocessing dataset\n",
      "Finished preprocessing dataset\n"
     ]
    }
   ],
   "source": [
    "gene_dataset = RetinaDataset(save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:  84%|████████▍ | 42/50 [2:18:09<26:18, 197.37s/it]  "
     ]
    }
   ],
   "source": [
    "n_epochs=50 if n_epochs_all is None else n_epochs_all\n",
    "lr=1e-3\n",
    "use_batches=True\n",
    "use_cuda=True\n",
    "\n",
    "### Train the model and output model likelihood every 5 epochs\n",
    "vae = VAE(gene_dataset.nb_genes, n_batch=gene_dataset.n_batches * use_batches)\n",
    "trainer = UnsupervisedTrainer(vae, \n",
    "                              gene_dataset, \n",
    "                              train_size=0.9, \n",
    "                              use_cuda=use_cuda,\n",
    "                              frequency=5)\n",
    "trainer.train(n_epochs=n_epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the likelihood change across the 50 epochs of training: blue for training error and orange for testing error. \n",
    "\n",
    "ll_train = trainer.history[\"ll_train_set\"]\n",
    "ll_test = trainer.history[\"ll_test_set\"]\n",
    "x = np.linspace(0,50,(len(ll_train)))\n",
    "plt.plot(x, ll_train)\n",
    "plt.plot(x, ll_test)\n",
    "plt.ylim(min(ll_train)-50, 3500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing batch mixing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entropy batch mixing :\", trainer.train_set.entropy_batch_mixing())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coloring by batch and cell type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining latent space in the same order as the input data\n",
    "trainer.train_set.show_t_sne(n_samples=n_samples_tsne, color_by='batches and labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allow_notebook_for_test():\n",
    "    print(\"Testing the basic tutorial notebook\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
